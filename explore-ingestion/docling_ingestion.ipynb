{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e97817e",
   "metadata": {},
   "source": [
    "# Document Ingestion with Docling\n",
    "\n",
    "This notebook explores document ingestion using the Docling library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d08a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08202a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../docs/DocLayNet.pdf\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Set the PDF path\n",
    "pdf_path = \"../docs/DocLayNet.pdf\"\n",
    "print(f\"Processing: {pdf_path}\")\n",
    "print(f\"File exists: {os.path.exists(pdf_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "694cbd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converter created\n"
     ]
    }
   ],
   "source": [
    "# Configure pipeline options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True  # Enable OCR, which may be needed for image extraction\n",
    "pipeline_options.do_table_structure = True  # Enable table structure detection\n",
    "\n",
    "# Create converter\n",
    "converter = DocumentConverter(\n",
    "    format_options={InputFormat.PDF: PdfFormatOption(\n",
    "        pipeline_options=pipeline_options,\n",
    "        backend=PyPdfiumDocumentBackend\n",
    "    )}\n",
    ")\n",
    "print(\"Converter created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01eb65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM model not available: No module named 'docling.models.granite_vlm_model'\n"
     ]
    }
   ],
   "source": [
    "# Try to import VLM model for image extraction\n",
    "try:\n",
    "    from docling.models.granite_vlm_model import GraniteDoclingModel\n",
    "    vlm_model = GraniteDoclingModel()\n",
    "    print(\"VLM model loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"VLM model not available: {e}\")\n",
    "    vlm_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf3fcaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-07 22:36:35,469 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,474 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,474 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,514 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,516 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,517 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,546 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,554 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:36:35,555 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful: success\n",
      "Document type: <class 'docling_core.types.doc.document.DoclingDocument'>\n",
      "Number of pages: 9\n"
     ]
    }
   ],
   "source": [
    "# Convert the document\n",
    "result = converter.convert(pdf_path)\n",
    "print(f\"Conversion successful: {result.status}\")\n",
    "document = result.document\n",
    "print(f\"Document type: {type(document)}\")\n",
    "print(f\"Number of pages: {len(document.pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf1b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text (first 1000 characters):\n",
      "## DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis\n",
      "\n",
      "Birgit Pfitzmann IBM Research Rueschlikon, Switzerland bpf@zurich.ibm.com\n",
      "\n",
      "Christoph Auer IBM Research Rueschlikon, Switzerland cau@zurich.ibm.com\n",
      "\n",
      "Ahmed S. Nassar IBM Research\n",
      "\n",
      "Rueschlikon, Switzerland ahn@zurich.ibm.com\n",
      "\n",
      "Michele Dolfi IBM Research Rueschlikon, Switzerland dol@zurich.ibm.com\n",
      "\n",
      "Peter Staar IBM Research Rueschlikon, Switzerland taa@zurich.ibm.com\n",
      "\n",
      "Figure 1: Four examples of complex page layouts across different document categories\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## KEYWORDS\n",
      "\n",
      "PDF document conversion, layout segmentation, object-detection, data set, Machine Learning\n",
      "\n",
      "## ACM Reference Format:\n",
      "\n",
      "Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. DocLayNet: A Large Human-Annotated Dataset for DocumentLayout Analysis. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22), August 14â€“18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 9\n"
     ]
    }
   ],
   "source": [
    "# Extract text\n",
    "full_text = document.export_to_markdown()\n",
    "print(\"Full text (first 1000 characters):\")\n",
    "print(full_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fccc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document body has 110 children\n",
      "Child 1: <class 'docling_core.types.doc.document.RefItem'> - cref='#/texts/0'...\n",
      "Child 2: <class 'docling_core.types.doc.document.RefItem'> - cref='#/texts/1'...\n",
      "Child 3: <class 'docling_core.types.doc.document.RefItem'> - cref='#/texts/2'...\n",
      "Child 4: <class 'docling_core.types.doc.document.RefItem'> - cref='#/texts/3'...\n",
      "Child 5: <class 'docling_core.types.doc.document.RefItem'> - cref='#/texts/4'...\n"
     ]
    }
   ],
   "source": [
    "# Explore document structure\n",
    "print(f\"Document body has {len(document.body.children)} children\")\n",
    "for i, child in enumerate(document.body.children[:5]):  # First 5\n",
    "    print(f\"Child {i+1}: {type(child)} - {str(child)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162c0406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables: 5\n",
      "First table:\n",
      "|                |         | % of Total         | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   |\n",
      "|----------------|---------|--------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
      "| class label    | Count   | Train Test Val     |                                             | All Fin Man Sci Law Pat Ten                 |                                             |                                             |                                             |                                             |                                             |\n",
      "| Caption        | 22524   | 2.04 1.77 2.32     |                                             | 84-89 40-61 86-92 94-99 95-99 69-78 n/a     |                                             |                                             |                                             |                                             |                                             |\n",
      "| Footnote       | 6318    | 0.60 0.31 0.58     |                                             | 83-91 n/a 100 62-88 85-94 n/a 82-97         |                                             |                                             |                                             |                                             |                                             |\n",
      "| Formula        | 25027   | 2.25 1.90 2.96     |                                             | 83-85 n/a n/a 84-87 86-96 n/a n/a           |                                             |                                             |                                             |                                             |                                             |\n",
      "| List-item      | 185660  | 17.19 13.34 15.82  |                                             | 87-88 74-83 90-92 97-97 81-85 75-88 93-95   |                                             |                                             |                                             |                                             |                                             |\n",
      "| Page-footer    | 70878   | 6.51 5.58 6.00     | 93-94 88-90 95-96 100 92-97 100 96-98       |                                             |                                             |                                             |                                             |                                             |                                             |\n",
      "| Page-header    | 58022   | 5.10 6.70 5.06     |                                             | 85-89 66-76 90-94 98-100 91-92 97-99 81-86  |                                             |                                             |                                             |                                             |                                             |\n",
      "| Picture        | 45976   | 4.21 2.78 5.31     |                                             | 69-71 56-59 82-86 69-82 80-95 66-71 59-76   |                                             |                                             |                                             |                                             |                                             |\n",
      "| Section-header | 142884  | 12.60 15.77 12.85  |                                             | 83-84 76-81 90-92 94-95 87-94 69-73 78-86   |                                             |                                             |                                             |                                             |                                             |\n",
      "| Table          | 34733   | 3.20 2.27 3.60     |                                             | 77-81 75-80 83-86 98-99 58-80 79-84 70-85   |                                             |                                             |                                             |                                             |                                             |\n",
      "| Text           | 510377  | 45.82 49.28 45.00  |                                             | 84-86 81-86 88-93 89-93 87-92 71-79 87-95   |                                             |                                             |                                             |                                             |                                             |\n",
      "| Title          | 5071    | 0.47 0.30 0.50     |                                             | 60-72 24-63 50-63 94-100 82-96 68-79 24-56  |                                             |                                             |                                             |                                             |                                             |\n",
      "| Total          | 1107470 | 941123 99816 66531 |                                             | 82-83 71-74 79-81 89-94 86-91 71-76 68-85   |                                             |                                             |                                             |                                             |                                             |\n"
     ]
    }
   ],
   "source": [
    "# Extract tables\n",
    "tables = document.tables\n",
    "print(f\"Number of tables: {len(tables)}\")\n",
    "if tables:\n",
    "    first_table = tables[0]\n",
    "    print(\"First table:\")\n",
    "    print(first_table.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34ef43f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 6\n",
      "Image info:\n",
      "Image 1: No URI - Figure 1: Four examples of complex page layouts across different document categories\n",
      "  No image data available - images may be vector graphics or text-based figures not extractable as bitmaps\n",
      "Image 2: No URI - Figure 2: Distribution of DocLayNet pages across document categories.\n",
      "  No image data available - images may be vector graphics or text-based figures not extractable as bitmaps\n",
      "Image 3: No URI - Figure 3: Corpus Conversion Service annotation user interface. The PDF page is shown in the background, with overlaid text-cells (in darker shades). The annotation boxes can be drawn by dragging a rectangle over each segment with the respective label from the palette on the right.\n",
      "  No image data available - images may be vector graphics or text-based figures not extractable as bitmaps\n"
     ]
    }
   ],
   "source": [
    "# Extract images (if any)\n",
    "images = document.pictures\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "if images:\n",
    "    print(\"Image info:\")\n",
    "    for i, img in enumerate(images[:3]):\n",
    "        uri = img.image.uri if img.image else \"No URI\"\n",
    "        caption = img.caption_text(document)\n",
    "        print(f\"Image {i+1}: {uri} - {caption}\")\n",
    "        # Try to get the image\n",
    "        pil_img = img.get_image(document)\n",
    "        if pil_img:\n",
    "            # Convert to base64\n",
    "            import io\n",
    "            import base64\n",
    "            buffer = io.BytesIO()\n",
    "            pil_img.save(buffer, format='PNG')\n",
    "            img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "            print(f\"  Base64: data:image/png;base64,{img_base64[:50]}...\")  # Show first 50 chars\n",
    "            # Display in notebook\n",
    "            from IPython.display import display, HTML\n",
    "            display(HTML(f'<img src=\"data:image/png;base64,{img_base64}\" width=\"200\"/>'))\n",
    "        else:\n",
    "            print(\"  No image data available - images may be vector graphics or text-based figures not extractable as bitmaps\")\n",
    "else:\n",
    "    print(\"No images found in the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2f4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error exporting to markdown: No module named 'docling_core.transforms.export'\n"
     ]
    }
   ],
   "source": [
    "# Try exporting to markdown with embedded images\n",
    "try:\n",
    "    from docling.datamodel.base_models import DocumentStream\n",
    "    from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "    from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "    from docling.document_converter import DocumentConverter, InputFormat\n",
    "    from docling.datamodel.document import ConversionResult\n",
    "    from docling_core.transforms.export.markdown import MarkdownExportConfig\n",
    "\n",
    "    # Create export config with embedded images\n",
    "    export_config = MarkdownExportConfig()\n",
    "    export_config.image_mode = \"embedded\"  # This should embed images as base64\n",
    "\n",
    "    # Export to markdown\n",
    "    markdown_output = document.export_to_markdown(export_config=export_config)\n",
    "    print(\"Markdown export with embedded images:\")\n",
    "    print(markdown_output[:2000])  # Show first 2000 chars\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error exporting to markdown: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b8a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-07 22:39:18,013 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,018 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,019 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,057 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,059 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,060 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,086 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,095 [RapidOCR] download_file.py:60: File exists and is valid: /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-07 22:39:18,096 [RapidOCR] main.py:53: Using /home/zord/learn-rag/venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default conversion successful\n",
      "Default conversion - Number of images: 6\n",
      "Image 1 not extracted: Figure 1: Four examples of complex page layouts ac...\n",
      "Image 2 not extracted: Figure 2: Distribution of DocLayNet pages across d...\n",
      "Image 3 not extracted: Figure 3: Corpus Conversion Service annotation use...\n"
     ]
    }
   ],
   "source": [
    "# Try with default converter (no custom pipeline options)\n",
    "try:\n",
    "    default_converter = DocumentConverter()\n",
    "    default_result = default_converter.convert(pdf_path)\n",
    "    default_document = default_result.document\n",
    "    print(\"Default conversion successful\")\n",
    "\n",
    "    # Check images with default settings\n",
    "    default_images = default_document.pictures\n",
    "    print(f\"Default conversion - Number of images: {len(default_images)}\")\n",
    "    if default_images:\n",
    "        for i, img in enumerate(default_images[:3]):\n",
    "            caption = img.caption_text(default_document)\n",
    "            pil_img = img.get_image(default_document)\n",
    "            if pil_img:\n",
    "                print(f\"Image {i+1} extracted successfully: {caption[:50]}...\")\n",
    "                # Convert to base64\n",
    "                import io\n",
    "                import base64\n",
    "                buffer = io.BytesIO()\n",
    "                pil_img.save(buffer, format='PNG')\n",
    "                img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "                print(f\"  Base64 length: {len(img_base64)} chars\")\n",
    "                # Display\n",
    "                from IPython.display import display, HTML\n",
    "                display(HTML(f'<img src=\"data:image/png;base64,{img_base64}\" width=\"200\"/>'))\n",
    "            else:\n",
    "                print(f\"Image {i+1} not extracted: {caption[:50]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error with default converter: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50174ad",
   "metadata": {},
   "source": [
    "## Notes on Image Extraction\n",
    "\n",
    "Docling successfully detected 6 images/figures in the PDF, including their captions and locations. However, the images are not extractable as bitmap images (PIL images) because they appear to be vector graphics or complex text-based figures rather than embedded raster images.\n",
    "\n",
    "- **Why this happens**: Docling's image extraction works best for embedded bitmap images in PDFs. Figures that are composed of vector paths, text, or complex layouts (like the examples in this academic paper) cannot be directly extracted as images.\n",
    "- **Why CLI might work**: The \"simple CLI docling\" you mentioned likely uses Vision-Language Model (VLM) processing, which can generate base64-encoded images from the PDF content. To enable this in code, you need to:\n",
    "  1. Install additional dependencies: `pip install transformers torch`\n",
    "  2. Use the GraniteDoclingModel: `from docling.models.granite_vlm_model import GraniteDoclingModel`\n",
    "  3. Set `pipeline_options.do_vlm = True` and `pipeline_options.vlm_model = GraniteDoclingModel()`\n",
    "- **Viewing the figures**: You can open the PDF file directly (`../docs/DocLayNet.pdf`) to view the figures.\n",
    "- **Alternative extraction**: If you need to extract page images or render figures, consider using libraries like PyMuPDF (`fitz`) or pdfplumber, which can render entire pages as images.\n",
    "\n",
    "The text and table extraction is working perfectly, and the document structure is well-parsed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
