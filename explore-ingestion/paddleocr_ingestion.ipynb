{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310df97d",
   "metadata": {},
   "source": [
    "# Document Ingestion with PaddleOCR\n",
    "\n",
    "This notebook explores OCR on images extracted from PDFs using PaddleOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97169c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install paddlepaddle paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb7b03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zord/learn-rag/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0ee6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zord/learn-rag/venv/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:712: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/zord/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/zord/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/zord/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/zord/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/zord/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize OCR (this downloads models)\n",
    "try:\n",
    "    ocr = PaddleOCR(use_textline_orientation=True, lang=\"en\")\n",
    "    print(\"OCR initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"OCR initialization failed: {e}\")\n",
    "    ocr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example image path (assuming images are extracted)\n",
    "# For demo, let's assume we have an image from PyMuPDF\n",
    "# img_path = \"extracted_outputs/images/page_1_img_1.png\"\n",
    "\n",
    "# Since we don't have images yet, let's create a dummy\n",
    "print(\"To use OCR, first extract images using PyMuPDF notebook, then run:\")\n",
    "print(\"result = ocr.ocr(img_path)\")\n",
    "print(\"for line in result:\")\n",
    "print(\"    for box in line:\")\n",
    "print(\"        print(box[1][0])  # text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de153c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109348/2848302123.py:3: DeprecationWarning: Please use `predict` instead.\n",
      "  result = ocr.ocr(\"./test.jpeg\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "(Unimplemented) ConvertPirAttribute2RuntimeAttribute not support [pir::ArrayAttribute<pir::DoubleAttribute>]  (at /paddle/paddle/fluid/framework/new_executor/instruction/onednn/onednn_instruction.cc:116)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If you have an image, uncomment and run\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ocr:\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mocr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./test.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m line:\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/typing_extensions.py:3004\u001b[0m, in \u001b[0;36mdeprecated.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3001\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   3002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3003\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 3004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddleocr/_pipelines/ocr.py:231\u001b[0m, in \u001b[0;36mPaddleOCR.ocr\u001b[0;34m(self, img, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `predict` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mocr\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddleocr/_pipelines/ocr.py:213\u001b[0m, in \u001b[0;36mPaddleOCR.predict\u001b[0;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, return_word_box)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m     return_word_box\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    212\u001b[0m ):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_textline_orientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_textline_orientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_word_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_word_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/pipelines/_parallel.py:139\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[0;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/pipelines/ocr/pipeline.py:357\u001b[0m, in \u001b[0;36m_OCRPipeline.predict\u001b[0;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_max_side_limit, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, return_word_box)\u001b[0m\n\u001b[1;32m    351\u001b[0m     doc_preprocessor_results \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: arr} \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m image_arrays]\n\u001b[1;32m    353\u001b[0m doc_preprocessor_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    354\u001b[0m     item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_img\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m doc_preprocessor_results\n\u001b[1;32m    355\u001b[0m ]\n\u001b[0;32m--> 357\u001b[0m det_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_det_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_preprocessor_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtext_det_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m dt_polys_list \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt_polys\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m det_results]\n\u001b[1;32m    363\u001b[0m dt_polys_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_boxes(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dt_polys_list]\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/models/base/predictor/base_predictor.py:281\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, input, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _apply(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/models/base/predictor/base_predictor.py:338\u001b[0m, in \u001b[0;36mBasePredictor.apply\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m--> 338\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m PredictionWrap(prediction, \u001b[38;5;28mlen\u001b[39m(batch_data))\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_data)):\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/models/text_detection/predictor.py:133\u001b[0m, in \u001b[0;36mTextDetPredictor.process\u001b[0;34m(self, batch_data, limit_side_len, limit_type, thresh, box_thresh, unclip_ratio, max_side_limit)\u001b[0m\n\u001b[1;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_tfs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m](imgs\u001b[38;5;241m=\u001b[39mbatch_imgs)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_static_model:\n\u001b[0;32m--> 133\u001b[0m     batch_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDeviceChanger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice):\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/models/common/static_infer.py:298\u001b[0m, in \u001b[0;36mPaddleInfer.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    296\u001b[0m x \u001b[38;5;241m=\u001b[39m _sort_inputs(x, names)\n\u001b[1;32m    297\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39mascontiguousarray, x))\n\u001b[0;32m--> 298\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/learn-rag/venv/lib/python3.10/site-packages/paddlex/inference/models/common/static_infer.py:261\u001b[0m, in \u001b[0;36mPaddleInferChainLegacy.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    259\u001b[0m     input_handle\u001b[38;5;241m.\u001b[39mreshape(input_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    260\u001b[0m     input_handle\u001b[38;5;241m.\u001b[39mcopy_from_cpu(input_)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [o\u001b[38;5;241m.\u001b[39mcopy_to_cpu() \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_handles]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: (Unimplemented) ConvertPirAttribute2RuntimeAttribute not support [pir::ArrayAttribute<pir::DoubleAttribute>]  (at /paddle/paddle/fluid/framework/new_executor/instruction/onednn/onednn_instruction.cc:116)\n"
     ]
    }
   ],
   "source": [
    "# If you have an image, uncomment and run\n",
    "if ocr:\n",
    "    result = ocr.ocr(\"./test.jpeg\")\n",
    "    for line in result:\n",
    "        for box in line:\n",
    "            print(box[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
